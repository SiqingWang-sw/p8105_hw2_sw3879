---
title: "p8105_hw2_sw3879"
author: "Siqing Wang"
date: "2023-09-27"
output: github_document
---

Importing libraries
```{r, message = FALSE}
library(tidyverse)
library(dplyr)
```
## Problem 1 

Read `pols-month.csv` into a dataframe and clean up data 

```{r, message = FALSE}
pols_month_df = 
  read_csv("data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-") |> 
  mutate(
    year = as.numeric(year),
    month = month.name[as.numeric(month)],
    president = ifelse(
      prez_gop > prez_dem, "gop", "dem"
    )
  ) |> 
  select(-day, -prez_gop, -prez_dem)
```

Cleaning data in `snp.csv`
```{r, message = FALSE}
snp_df = 
  read_csv("data/snp.csv") |> 
  janitor::clean_names() |> 
  mutate(
    date = format(as.Date(date, format = "%m/%d/%y"), "%Y/%m/%d")
  ) |> 
  separate(date, into = c("year", "month", "day"), sep = "/") |> 
  mutate(
    month = month.name[as.numeric(month)],
    year = as.numeric(year),
    year = ifelse(year > 2023, year - 100, year)
  ) |> 
  select(-day)
```

Pivoting `unemployment.csv` to long format
```{r, message = FALSE}
unemployment_df = 
  read_csv("data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) |> 
  mutate(
    year = as.numeric(year),
    month = month.name[match(month, tolower(month.abb))]
  )
```

Merging the 3 datasets
```{r, message = FALSE}
result_df = left_join(pols_month_df,snp_df, by = c("year", "month")) |> 
  left_join(unemployment_df, by = c("year", "month"))
```

TO DO: INSERT DESCRIPTION

## Problem 2

Read in the Mr. Trash Wheel sheet 
```{r, message = FALSE}
trash_wheel_df = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = "Mr. Trash Wheel", skip = 1) |> 
   janitor::clean_names() |>
  drop_na(dumpster) |> 
  select(-x15, -x16) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    trash_wheel_name = "Mr. Trash Wheel",
    year = as.numeric(year)
  )
```

Read in professor trash wheel and gwynnda 
```{r, message = FALSE}
gwynnda_trash_wheel_df = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = "Gwynnda Trash Wheel", skip = 1) |> 
   janitor::clean_names() |>
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    trash_wheel_name = "Gwynnda Trash Wheel",
    year = as.numeric(year)
  )

prof_trash_wheel_df = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = "Professor Trash Wheel", skip = 1) |> 
   janitor::clean_names() |>
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    trash_wheel_name = "Professor Trash Wheel",
    year = as.numeric(year)
  )
```

Combining three datasets
```{r}
trashwheel_master = bind_rows(trash_wheel_df, prof_trash_wheel_df, gwynnda_trash_wheel_df)
```

TO DO: add descriptions to datasets 

The combined master datasets for trash wheel has `r nrow(trashwheel_master)` rows and `r ncol(trashwheel_master)` columns. 

The total weight of trash collected by Professor trash wheel is 
`r subset(trashwheel_master, trash_wheel_name == "Professor Trash Wheel") |> pull(weight_tons) |> sum()` tons.

the total number of cigarette butts collected by Gwynnda in July of 2021 is 
`r subset(gwynnda_trash_wheel_df, year == 2021 & month == "July") |> pull(cigarette_butts) |> sum() |> as.integer()`.

## Problem 3
Reading in baseline csv
```{r}
baseline = 
  read_csv("data/MCI_baseline.csv", skip = 1) |> 
  janitor::clean_names() |> 
  mutate(
    sex = case_match(
      sex,
      1 ~ "male",
      0 ~ "female"
    ),
    apoe4 = case_match(
      apoe4,
      1 ~ "carrier",
      0 ~ "non-carrier"
    )
  ) |> 
  filter(age_at_onset == "." | age_at_onset > current_age)
```

`r nrow(baseline)` were recruited at baseline. 

`r filter(baseline, age_at_onset != ".") |> nrow()` participants developed MCI during the study.

The average baseline age is `r mean(pull(baseline, current_age)) |> round(digits = 0)`.

Proportion of women who are APOE 4 carrier is 
`r scales::percent(nrow(filter(baseline, sex == "female" & apoe4 =="carrier")) / nrow(filter(baseline, sex == "female")))`.

```{r}
amyloid = 
  read_csv("data/mci_amyloid.csv", skip = 1) |> 
  janitor::clean_names() |> 
  rename("id" = "study_id")
```

Merge the longitudinal dataset with baseline, keeping all participants in both datasets
```{r}
amyloid_full = 
  full_join(baseline, amyloid, by = c("id"))
```

There are `r nrow(amyloid_full) - nrow(baseline)` participants in the baseline set but not in the amyloid set. 

There are `r nrow(amyloid_full) - nrow(amyloid)` participants in the amyloid set but not in the baseline set. 

Merge the longitudinal dataset with baseline to keep those in both datasets
```{r}
amyloid_both = 
  inner_join(baseline, amyloid, by = c("id"))
```

There are `r nrow(amyloid_both)` participants that are in both the baseline and longitudinal visit datasets, and there are `r ncol(amyloid_both)` columns. 

TO DO ask TA:

1. Check whether some participants appear in only the baseline or amyloid datasets. Should we include participants who are ineligible?

2. Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker value. Should we remove rows with missing value in a timepoint? 






