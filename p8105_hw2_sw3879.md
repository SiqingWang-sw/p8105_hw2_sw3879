p8105_hw2_sw3879
================
Siqing Wang
2023-09-27

Importing libraries

``` r
library(tidyverse)
library(dplyr)
```

## Problem 1

Read `pols-month.csv` into a dataframe and clean up data

``` r
pols_month_df = 
  read_csv("data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-") |> 
  mutate(
    year = as.numeric(year),
    month = month.name[as.numeric(month)],
    president = ifelse(
      prez_gop > prez_dem, "gop", "dem"
    )
  ) |> 
  select(-day, -prez_gop, -prez_dem)
```

Cleaning data in `snp.csv`

``` r
snp_df = 
  read_csv("data/snp.csv") |> 
  janitor::clean_names() |> 
  mutate(
    date = format(as.Date(date, format = "%m/%d/%y"), "%Y/%m/%d")
  ) |> 
  separate(date, into = c("year", "month", "day"), sep = "/") |> 
  mutate(
    month = month.name[as.numeric(month)],
    year = as.numeric(year),
    year = ifelse(year > 2023, year - 100, year)
  ) |> 
  select(-day)
```

Pivoting `unemployment.csv` to long format

``` r
unemployment_df = 
  read_csv("data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) |> 
  mutate(
    year = as.numeric(year),
    month = month.name[match(month, tolower(month.abb))]
  )
```

Merging the 3 datasets

``` r
result_df = left_join(pols_month_df,snp_df, by = c("year", "month")) |> 
  left_join(unemployment_df, by = c("year", "month"))
```

TO DO: INSERT DESCRIPTION

## Problem 2

Read in the Mr. Trash Wheel sheet

``` r
trash_wheel_df = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = "Mr. Trash Wheel", skip = 1) |> 
   janitor::clean_names() |>
  drop_na(dumpster) |> 
  select(-x15, -x16) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    trash_wheel_name = "Mr. Trash Wheel",
    year = as.numeric(year)
  )
```

Read in professor trash wheel and gwynnda

``` r
gwynnda_trash_wheel_df = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = "Gwynnda Trash Wheel", skip = 1) |> 
   janitor::clean_names() |>
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    trash_wheel_name = "Gwynnda Trash Wheel",
    year = as.numeric(year)
  )

prof_trash_wheel_df = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = "Professor Trash Wheel", skip = 1) |> 
   janitor::clean_names() |>
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    trash_wheel_name = "Professor Trash Wheel",
    year = as.numeric(year)
  )
```

Combining three datasets

``` r
trashwheel_master = bind_rows(trash_wheel_df, prof_trash_wheel_df, gwynnda_trash_wheel_df)
```

TO DO: add descriptions to datasets

The combined master datasets for trash wheel has 845 rows and 15
columns.

The total weight of trash collected by Professor trash wheel is 216.26
tons.

the total number of cigarette butts collected by Gwynnda in July of 2021
is 16300.

## Problem 3

Reading in baseline csv

``` r
baseline = 
  read_csv("data/MCI_baseline.csv", skip = 1) |> 
  janitor::clean_names() |> 
  mutate(
    sex = case_match(
      sex,
      1 ~ "male",
      0 ~ "female"
    ),
    apoe4 = case_match(
      apoe4,
      1 ~ "carrier",
      0 ~ "non-carrier"
    )
  ) |> 
  filter(age_at_onset == "." | age_at_onset > current_age)
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

479 were recruited at baseline.

93 participants developed MCI during the study.

The average baseline age is 65.

Proportion of women who are APOE 4 carrier is 30%.

``` r
amyloid = 
  read_csv("data/mci_amyloid.csv", skip = 1) |> 
  janitor::clean_names() |> 
  rename("id" = "study_id")
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Merge the longitudinal dataset with baseline, keeping all participants
in both datasets

``` r
amyloid_full = 
  full_join(baseline, amyloid, by = c("id"))
```

There are 16 participants in the baseline set but not in the amyloid
set.

There are 8 participants in the amyloid set but not in the baseline set.

Merge the longitudinal dataset with baseline to keep those in both
datasets

``` r
amyloid_both = 
  inner_join(baseline, amyloid, by = c("id"))
```

There are 471 participants that are in both the baseline and
longitudinal visit datasets, and there are 11 columns.

TO DO ask TA:

1.  Check whether some participants appear in only the baseline or
    amyloid datasets. Should we include participants who are ineligible?

2.  Similarly, import, clean, and tidy the dataset of longitudinally
    observed biomarker value. Should we remove rows with missing value
    in a timepoint?
